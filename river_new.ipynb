{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary files.\n",
    "\n",
    "from openpiv import tools, pyprocess, validation, filters, scaling \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import imageio\n",
    "import json\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize or read all the confiugration values\n",
    "\n",
    "# Directory of the project\n",
    "BASE_DIR = 'E:/flow/project/'\n",
    "\n",
    "# Directory where video is kept\n",
    "INPUT_DIR = BASE_DIR + ''\n",
    "\n",
    "#Directory where images are stored\n",
    "IMAGE_DIR = BASE_DIR + 'images/'\n",
    "\n",
    "#Directory where substracted images are stored\n",
    "SUB_DIR = BASE_DIR + 'subs/'\n",
    "\n",
    "image_count = len([f for f in listdir(SUB_DIR) if isfile(join(SUB_DIR, f))]) - 2\n",
    "print(image_count)\n",
    "\n",
    "\n",
    "\n",
    "# Read the configuration file for threshold\n",
    "config_file = open(BASE_DIR + 'config/config.json')\n",
    "data = json.load(config_file)\n",
    "thr_v = data[\"threshold_v\"]\n",
    "thr_u = data[\"threshold_u\"]\n",
    "print(thr_v)\n",
    "print(thr_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Arrays for storing cumulative data.\n",
    "master_x=None\n",
    "master_y=None\n",
    "master_u=None\n",
    "master_v=None\n",
    "master_s2n=None\n",
    "\n",
    "\n",
    "# Read the first two frames\n",
    "first_frame = tools.imread(BASE_DIR + 'subs/sub_000.jpg')\n",
    "second_frame = tools.imread(BASE_DIR + 'subs/sub_001.jpg')\n",
    "\n",
    "\n",
    "# Analysis Parameters to be passed into the algorithm\n",
    "w_size = 32 # pixels, interrogation window size of first frame\n",
    "s_size = 38  # pixels, interrogation window size of second frame\n",
    "overlap = 12 # pixels, 50% overlap\n",
    "dt = 0.02 # sec, time interval between successive frames.\n",
    "\n",
    "\n",
    "u0, v0, sig2noise = pyprocess.extended_search_area_piv(first_frame.astype(np.int32), \n",
    "                                                           second_frame.astype(np.int32), \n",
    "                                                           window_size=w_size, \n",
    "                                                           overlap=overlap, \n",
    "                                                           dt=dt, \n",
    "                                                           search_area_size=s_size, \n",
    "                                                           sig2noise_method='peak2peak')\n",
    "\n",
    "x, y = pyprocess.get_coordinates( image_size=first_frame.shape, \n",
    "                                     search_area_size=s_size, \n",
    "                                     overlap=overlap )\n",
    "\n",
    "# Initialize the vectors from the first frame\n",
    "master_x = x\n",
    "master_y = y\n",
    "master_u = u0\n",
    "master_v = v0\n",
    "master_s2n = sig2noise\n",
    "\n",
    "# Run the analytics for rest of the images\n",
    "for index in range(1,image_count):\n",
    "    first_frame = tools.imread(SUB_DIR + 'sub_' + str(f\"{index:003}\")+'.jpg')\n",
    "    second_frame = tools.imread(SUB_DIR + 'sub_' + str(f\"{(index+1):003}\")+'.jpg')\n",
    "    print(SUB_DIR  + 'sub_'+str(f\"{(index+1):003}\")+'.jpg')\n",
    "\n",
    "    \n",
    "    u0, v0, sig2noise = pyprocess.extended_search_area_piv(first_frame.astype(np.int32), \n",
    "                                                           second_frame.astype(np.int32), \n",
    "                                                           window_size=w_size, \n",
    "                                                           overlap=overlap, \n",
    "                                                           dt=dt, \n",
    "                                                           search_area_size=s_size, \n",
    "                                                           sig2noise_method='peak2peak')\n",
    "    \n",
    "    x, y = pyprocess.get_coordinates( image_size=first_frame.shape, \n",
    "                                     search_area_size=s_size, \n",
    "                                     overlap=overlap )\n",
    "    \n",
    "    # Add vector for this frame to the consolidated vector\n",
    "    master_x = np.concatenate((master_x,x))\n",
    "    master_y = np.concatenate((master_y,y))\n",
    "    master_u = np.concatenate((master_u,u0))\n",
    "    master_v = np.concatenate((master_v,v0))\n",
    "    master_s2n = np.concatenate((master_s2n,sig2noise))\n",
    "    \n",
    "# At this point of time, we have the conslidated vectors for all frames, not run the post processing on those vectors\n",
    "\n",
    "u1, v1, mask = validation.sig2noise_val( master_u, master_v, \n",
    "                                        master_s2n, \n",
    "                                        threshold = 1.3 )\n",
    "\n",
    "\n",
    "tools.save(master_x, master_y, u1, v1, mask, 'raw_vector.txt' )\n",
    "    \n",
    "# filter out outliers that are very different from the\n",
    "# neighbours\n",
    "\n",
    "u2, v2 = filters.replace_outliers( u1, v1, \n",
    "                                  method='localmean', \n",
    "                                  max_iter=3, \n",
    "                                  kernel_size=3)\n",
    "\n",
    "# convert x,y to mm\n",
    "# convert u,v to mm/sec\n",
    "\n",
    "x, y, u3, v3 = scaling.uniform(master_x, master_y, u2, v2, \n",
    "                               scaling_factor = 96.52 ) # 96.52 microns/pixel\n",
    "\n",
    "# 0,0 shall be bottom left, positive rotation rate is counterclockwise\n",
    "x, y, u3, v3 = tools.transform_coordinates(x, y, u3, v3)\n",
    "\n",
    "#save in the simple ASCII table format\n",
    "tools.save(x, y, u3, v3, mask, 'processed_vector.txt' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ceb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(u3,v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all negative and noise vectors\n",
    "dest_file = open('filtered_vector.txt',\"w\")\n",
    "u_vector = []\n",
    "v_vector = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "\n",
    "with open('processed_vector.txt','r') as source_file:\n",
    "    for line in source_file:\n",
    "        #if ('1.0000' not in line and '-' not in line and 'x' not in line):\n",
    "        if ('1.0000' not in line and  'x' not in line):\n",
    "            dest_file.write(line)\n",
    "            values = line.split()\n",
    "            x_val.append(float(values[0]))\n",
    "            y_val.append(float(values[1]))\n",
    "            u_vector.append(float(values[2]))\n",
    "            v_vector.append(float(values[3]))\n",
    "\n",
    "dest_file.close()\n",
    "\n",
    "average_u = sum(u_vector) / float(len(u_vector))\n",
    "average_v = sum(v_vector) / float(len(v_vector))\n",
    "\n",
    "print(average_u)\n",
    "print(average_v)\n",
    "\n",
    "dest_file = open('average_vector.txt',\"w\")\n",
    "\n",
    "'''\n",
    "for i in range(0, len(x_val)):\n",
    "    if(v_vector[i] > 0):\n",
    "        line = str(x_val[i]) + \"    \" + str(y_val[i]) + \"    \" + str(u_vector[i]) + \"    \" + str(v_vector[i]) + \"    0.0000\\n\"\n",
    "        dest_file.write(line)\n",
    "'''\n",
    "\n",
    "for i in range(0, len(x_val)):\n",
    "    if(v_vector[i] > 0):\n",
    "        line = str(x_val[i]) + \"    \" + str(y_val[i]) + \"    \" + str(u_vector[i]*average_u/abs(u_vector[i])) + \"    \" + str(v_vector[i]*average_v/abs(v_vector[i])) + \"    0.0000\\n\"\n",
    "        dest_file.write(line)\n",
    "\n",
    "\n",
    "dest_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870da419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "tools.display_vector_field('processed_vector.txt', \n",
    "                           ax=ax, scaling_factor=96.52, \n",
    "                           scale=200, # scale defines here the arrow length\n",
    "                           width=0.0035, # width is the thickness of the arrow\n",
    "                           on_img=True, # overlay on the image\n",
    "                           image_name=BASE_DIR + 'images/frame_000.jpg');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80446fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "tools.display_vector_field('filtered_vector.txt', \n",
    "                           ax=ax, scaling_factor=96.52, \n",
    "                           scale=100, # scale defines here the arrow length\n",
    "                           width=0.004, # width is the thickness of the arrow\n",
    "                           on_img=False, # overlay on the image\n",
    "                           image_name=BASE_DIR + 'images/frame_000.jpg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3663517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "tools.display_vector_field('average_vector.txt', \n",
    "                           ax=ax, scaling_factor=96.52, \n",
    "                           scale=5, # scale defines here the arrow length\n",
    "                           width=0.004, # width is the thickness of the arrow\n",
    "                           on_img=False, # overlay on the image\n",
    "                           image_name=BASE_DIR + 'images/frame_000.jpg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a3891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
